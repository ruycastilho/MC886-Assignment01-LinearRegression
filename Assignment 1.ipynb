{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def load_diamond_data():\n",
    "    csv_path = os.path.join(\"diamonds-dataset\", \"diamonds-train.csv\")\n",
    "    return pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carrega os dados de treino e faz feature scaling(depth, table)\n",
    "import numpy as np\n",
    "diamond_data = load_diamond_data()\n",
    "diamond_data[\"depth\"] = (diamond_data[\"depth\"] / 10)\n",
    "diamond_data[\"table\"] = (diamond_data[\"table\"] / 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#dummy coding(cut,color,clarity)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "diamond_data = load_diamond_data()\n",
    "diamond_data[\"depth\"] = diamond_data[\"depth\"] / 10\n",
    "diamond_data[\"table\"] = diamond_data[\"table\"] / 10\n",
    "\n",
    "enumValues = {\"cut\": {\"Fair\":0, \"Good\":1, \"Very Good\":2, \"Premium\":3, \"Ideal\":4},\n",
    "              \"color\": {\"J\": 0, \"I\":1, \"H\":2, \"G\":3, \"F\":4, \"E\":5, \"D\":6},\n",
    "              \"clarity\": {\"I1\":0, \"SI2\":1, \"SI1\":2, \"VS2\":3, \"VS1\":4,\"VVS2\":5, \"VVS1\":6, \"IF\":7}}\n",
    "diamond_data.replace(enumValues, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal Equation\n",
    "\n",
    "def NormalEquation(X, y):\n",
    "\n",
    "    transpose = X.T\n",
    "\n",
    "    mult1 = transpose.dot(X)\n",
    "\n",
    "    try:\n",
    "        inverse = np.linalg.inv(mult1)\n",
    "\n",
    "    except np.linalg.LinAlgError:\n",
    "        print(\"Not invertible\")\n",
    "        return np.zeros(1,1)\n",
    "\n",
    "    else:\n",
    "        mult2 = (inverse.dot(transpose)).dot(y)\n",
    "        return mult2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#function add a first column filled with 1's and delete de last colum\n",
    "def prepareSet(setToPrepare):\n",
    "    X = np.array(setToPrepare)\n",
    "\n",
    "    X = np.delete(X, -1, axis=1)\n",
    "\n",
    "    X = np.c_[np.ones((len(X), 1)),X]\n",
    "\n",
    "    y = np.array(setToPrepare[\"price\"])\n",
    "\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #grafico Carat X Price\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.scatter(diamond_data[\"carat\"], diamond_data[\"price\"])\n",
    "# plt.xlabel(\"$carat$\", fontsize=18)\n",
    "# plt.ylabel(\"$price(U$)$\", fontsize=18)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #grafico Cut X Price\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.scatter(diamond_data[\"cut\"], diamond_data[\"price\"])\n",
    "# plt.xlabel(\"$cut$\", fontsize=18)\n",
    "# plt.ylabel(\"$price$\", fontsize=18)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #grafico  Color X Price\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.scatter(diamond_data[\"color\"], diamond_data[\"price\"])\n",
    "# plt.xlabel(\"$color$\", fontsize=18)\n",
    "# plt.ylabel(\"$price$\", fontsize=18)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #grafico Clarity X Price\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.scatter(diamond_data[\"clarity\"], diamond_data[\"price\"])\n",
    "# plt.xlabel(\"$clarity$\", fontsize=18)\n",
    "# plt.ylabel(\"$price$\", fontsize=18)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #grafico Depth X Price\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.scatter(diamond_data[\"depth\"], diamond_data[\"price\"])\n",
    "# plt.xlabel(\"$depth$\", fontsize=18)\n",
    "# plt.ylabel(\"$price$\", fontsize=18)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #grafico table X Price\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.scatter(diamond_data[\"table\"], diamond_data[\"price\"])\n",
    "# plt.xlabel(\"$table$\", fontsize=18)\n",
    "# plt.ylabel(\"$price$\", fontsize=18)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #grafico x X Price\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.scatter(diamond_data[\"x\"], diamond_data[\"price\"])\n",
    "# plt.xlabel(\"$x$\", fontsize=18)\n",
    "# plt.ylabel(\"$price$\", fontsize=18)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #grafico y X Price\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.scatter(diamond_data[\"y\"], diamond_data[\"price\"])\n",
    "# plt.xlabel(\"$y$\", fontsize=18)\n",
    "# plt.ylabel(\"$price$\", fontsize=18)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #grafico z X Price\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.scatter(diamond_data[\"z\"], diamond_data[\"price\"])\n",
    "# plt.xlabel(\"$z$\", fontsize=18)\n",
    "# plt.ylabel(\"$price$\", fontsize=18)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation Generation\n",
    "\n",
    "# PRECISA CHAMAR ISSO ANTES DE CHAMAR A FUNCAO --- \n",
    "#                             TRAINING_DATA = prepareSet(diamond_data) \n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "#essa funcao retorna um gerador de indices\n",
    "def generate_sets(TRAINING_DATA,type='kfold'):\n",
    "\n",
    "    # Cross validation using train_test_split\n",
    "    if (type == 'split'):\n",
    "       return train_test_split(TRAINING_DATA,test_size=0.2,random_state=0)\n",
    "\n",
    "    # Cross validation using K-Fold\n",
    "    # K = 5, Shuffle = true, Seed = 21\n",
    "    elif (type == 'kfold'):\n",
    "        kfold_seed = 21\n",
    "\n",
    "        kfold = KFold(n_splits=5, shuffle=True, random_state=kfold_seed)\n",
    "        return kfold.split(TRAINING_DATA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explicação do uso do generate_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# import numpy as np\n",
    "# from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "# X = np.array([[10, 20], [30, 40], [50, 60], [70, 80], [90, 100], [110, 120], [130, 140], [150, 160], [170, 180], [190, 200]])\n",
    "# y = np.array(['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j'])\n",
    "\n",
    "# #esse b vai ser um gerador, não precisa passar y pois ele gera somente os indices\n",
    "# b = generate_sets(X)\n",
    "\n",
    "# #precisa percorrer ele com 2 indices, um representa o treino, outro o test, \n",
    "# # na proxima iteracao ele ja vai estar num agrupamento diferente\n",
    "# for train_index, val_index in b:\n",
    "#     x_train = X[train_index]\n",
    "#     y_train = y[train_index]\n",
    "#     x_val = X[val_index]\n",
    "#     y_val = y[val_index]\n",
    "#     print(x_train, y_train)\n",
    "#     print(x_val, y_val)\n",
    "#     print(\"-----\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implementation Linear Regression using Mini-Batch Gradient Descent\n",
    "def LinRegMiniGradientDescent(TRAIN_SET, TARGET_SET, N_ITERATION, LEARNING_RATE, SIZE_BATCH):\n",
    "    np.random.seed(42)\n",
    "    theta = np.random.randn(10,1) #random initialization\n",
    "    for iteration in range(N_ITERATIONS):\n",
    "        shuffle_indices = np.random.permutation(TRAIN_SET.shape[0])\n",
    "        train_shuffled = TRAIN_SET[shuffled_indices]\n",
    "        target_shuffled = TARGET_SET[shuffled_indices]\n",
    "        for i in range(0,TARGET_SET.shape[0], SIZE_BATCH):\n",
    "            xi = train_shuffled[i:i+SIZE_BATCH]\n",
    "            yi = target_shuffled[i:i+SIZE_BATCH]\n",
    "            gradients = 2/SIZE_BATCH * xi.T.dot(xi.dot(theta) - yi)\n",
    "            theta = theta - LEARNING_RATE * gradients\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "def LinRegBatchGradientDescent(x, y, numIterations, learningRate):\n",
    "    xTrans = x.transpose()\n",
    "    theta = np.random.randn(x.shape[1],1) #random initialization\n",
    "    m = x.shape[0]\n",
    "    y = y.reshape((y.shape[0],1))\n",
    "    for i in range(numIterations):\n",
    "        hypothesis = np.dot(x, theta)\n",
    "        loss = hypothesis - y\n",
    "        cost = np.sum(loss ** 2) / (2 * m)\n",
    "        gradient = np.dot(xTrans, loss) / m\n",
    "        theta = theta - learningRate * gradient\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "def LinRegBatchGradientDescentCostPerIteraction(x, y, numIterations, learningRate):\n",
    "    xTrans = x.transpose()\n",
    "    theta = np.random.randn(x.shape[1],1) #random initialization\n",
    "    m = x.shape[0]\n",
    "    y = y.reshape((y.shape[0],1))\n",
    "    cost = np.zeros((numIterations,1))\n",
    "    for i in range(numIterations):\n",
    "        hypothesis = np.dot(x, theta)\n",
    "        loss = hypothesis - y\n",
    "        cost[i] = np.sum(loss ** 2) / (2 * m)\n",
    "        gradient = np.dot(xTrans, loss) / m\n",
    "        theta = theta - learningRate * gradient\n",
    "    return theta, cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proximos 4 celulas e pra mostrar que o nosso LinRegBatchGradientDescent funciona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "##DATA SET PARA testar A FUNCAO DEPOIS\n",
    "import numpy as np\n",
    "import numpy.random as rnd\n",
    "\n",
    "np.random.seed(42)\n",
    "X = 2 * rnd.rand(100,1)\n",
    "y = 4 + 3 * X + rnd.randn(100,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.21509616],\n",
       "       [2.77011339]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy.linalg as LA\n",
    "\n",
    "X_b = np.c_[np.ones((100, 1)), X] # add x0 = 1 to each instance\n",
    "theta_best = LA.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y)\n",
    "theta_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4.21413037]), array([2.77067691]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "sgd_reg = SGDRegressor(max_iter=1000, penalty=None, eta0=0.1)\n",
    "sgd_reg.fit(X, y.ravel())\n",
    "sgd_reg.intercept_, sgd_reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta, error = LinRegBatchGradientDescent(X_b,y,100,0.1)\n",
    "type(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotar CostFunction x Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as pd\n",
    "# %matplotlib inline\n",
    "# theta, error = LinRegBatchGradientDescent(X_b,y,100,0.1)\n",
    "# print(theta)\n",
    "# plt.plot(np.arange(error.shape[0]) ,error)\n",
    "# plt.ylabel('Cost Function')\n",
    "# plt.xlabel('Iterations')\n",
    "# plt.axis([0,20,0,100])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ideias de modelos\n",
    "usando todas as features\n",
    "<br>\n",
    "&nbsp;&nbsp;normal\n",
    "&nbsp;&nbsp;ao quadrado\n",
    "<br>\n",
    "tirando as features que nao aparentam influenciar\n",
    "<br>\n",
    "&nbsp;&nbsp;normal\n",
    "&nbsp;&nbsp; ao quadrado\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODELO 1 : Modelo com todas as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "x1,y1 = prepareSet(diamond_data)\n",
    "indices_generator = generate_sets(x1)\n",
    "theta1 = np.zeros((5,x1.shape[1],1))\n",
    "error1 = np.zeros((5,1))\n",
    "error1_n = np.zeros((5,1)) \n",
    "i=0\n",
    "for train_index, val_index in indices_generator:\n",
    "    #dados de treino e de validacao\n",
    "    x1_train = x1[train_index]\n",
    "    y1_train = y1[train_index]\n",
    "    x1_val = x1[val_index]\n",
    "    y1_val = y1[val_index]\n",
    "     \n",
    "    theta1[i] = LinRegBatchGradientDescent(x1_train,y1_train,10000,0.01)\n",
    "    thetaNormal = NormalEquation(x1_train,y1_train)\n",
    "    \n",
    "    #error from validation\n",
    "    y1_predict = x1_val.dot(theta1[i])\n",
    "    y1_n_predict = x1_val.dot(thetaNormal)\n",
    "    error1[i] = mean_squared_error(y1_val, y1_predict)\n",
    "    error1_n[i] = mean_squared_error(y1_val, y1_n_predict)/2\n",
    "    i += 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteracao  1\n",
      "\tErro pelo Gradient Descent: 1600877\n",
      "\tErro pela Equacao Normal:    724963\n",
      "Iteracao  2\n",
      "\tErro pelo Gradient Descent: 1613201\n",
      "\tErro pela Equacao Normal:    732478\n",
      "Iteracao  3\n",
      "\tErro pelo Gradient Descent: 1699356\n",
      "\tErro pela Equacao Normal:    771709\n",
      "Iteracao  4\n",
      "\tErro pelo Gradient Descent: 1689004\n",
      "\tErro pela Equacao Normal:    897075\n",
      "Iteracao  5\n",
      "\tErro pelo Gradient Descent: 1580719\n",
      "\tErro pela Equacao Normal:    720242\n",
      "Media erros GD: 1636631\n",
      "Media erros EN:  769293\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=1)\n",
    "for i in range(5):\n",
    "    print(\"Iteracao \", i+1,)\n",
    "    print(\"\\tErro pelo Gradient Descent:\", int(error1[i]) )\n",
    "    print(\"\\tErro pela Equacao Normal:   \" , int(error1_n[i]) )\n",
    "\n",
    "print(\"Media erros GD:\", int(np.mean(error1)) )\n",
    "print(\"Media erros EN: \", int(np.mean(error1_n)) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_generator = generate_sets(x1)\n",
    "theta1 = np.zeros((5,x1.shape[1],1))\n",
    "error1 = np.zeros((5,1))\n",
    "error1_n = np.zeros((5,1)) \n",
    "i=0\n",
    "for train_index, val_index in indices_generator:\n",
    "    #dados de treino e de validacao\n",
    "    x1_train = x1[train_index]\n",
    "    y1_train = y1[train_index]\n",
    "    x1_val = x1[val_index]\n",
    "    y1_val = y1[val_index]\n",
    "     \n",
    "    theta1[i],cost = LinRegBatchGradientDescentCostPerIteraction(x1_train,y1_train,10000,0.1)\n",
    "    \n",
    "    #error from validation\n",
    "    y1_predict = x1_val.dot(theta1[i])\n",
    "    error1[i] = mean_squared_error(y1_val, y1_predict)\n",
    "\n",
    "    i += 1\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2000, 0, 10000000]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as pd\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(range(cost.shape[0]) ,cost)\n",
    "plt.ylabel('Cost Function')\n",
    "plt.xlabel('Iterations')\n",
    "plt.axis([0,2000,0,10000000])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo 2: sem as features que nao aparentam ter significado no resultado (table,depth,clarity,color,cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "data = diamond_data[['x', 'y', 'z', 'carat', 'price']]\n",
    "x2,y2 = prepareSet(data)\n",
    "indices_generator = generate_sets(x2)\n",
    "theta2 = np.zeros((5,x2.shape[1],1))\n",
    "error2 = np.zeros((5,1))\n",
    "error2_n = np.zeros((5,1)) \n",
    "i=0\n",
    "for train_index, val_index in indices_generator:\n",
    "    #dados de treino e de validacao\n",
    "    x2_train = x2[train_index]\n",
    "    y2_train = y2[train_index]\n",
    "    x2_val = x2[val_index]\n",
    "    y2_val = y2[val_index]\n",
    "     \n",
    "    theta2[i] = LinRegBatchGradientDescent(x2_train,y2_train,10000,0.001)\n",
    "    thetaNormal = NormalEquation(x2_train,y2_train)\n",
    "    \n",
    "    #error from validation\n",
    "    y2_predict = x2_val.dot(theta2[i])\n",
    "    y2_n_predict = x2_val.dot(thetaNormal)\n",
    "    error2[i] = mean_squared_error(y2_val, y2_predict)\n",
    "    error2_n[i] = mean_squared_error(y2_val, y2_n_predict)/2\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteracao  1\n",
      "\tErro pelo Gradient Descent: 2876822\n",
      "\tErro pela Equacao Normal:   1109230\n",
      "Iteracao  2\n",
      "\tErro pelo Gradient Descent: 3033826\n",
      "\tErro pela Equacao Normal:   1155806\n",
      "Iteracao  3\n",
      "\tErro pelo Gradient Descent: 3154459\n",
      "\tErro pela Equacao Normal:   1188962\n",
      "Iteracao  4\n",
      "\tErro pelo Gradient Descent: 3074598\n",
      "\tErro pela Equacao Normal:   1886008\n",
      "Iteracao  5\n",
      "\tErro pelo Gradient Descent: 2940102\n",
      "\tErro pela Equacao Normal:   1141531\n",
      "Media erros GD: 3015961\n",
      "Media erros EN: 1296307\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=1)\n",
    "for i in range(5):\n",
    "    print(\"Iteracao \", i+1,)\n",
    "    print(\"\\tErro pelo Gradient Descent:\", int(error2[i]) )\n",
    "    print(\"\\tErro pela Equacao Normal:  \" , int(error2_n[i]) )\n",
    "\n",
    "print(\"Media erros GD:\", int(np.mean(error2)) )\n",
    "print(\"Media erros EN:\", int(np.mean(error2_n)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo 3 : sem as features que nao aparentam ter significado no resultado, so que com elas ao quadrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pedro/.local/lib/python3.6/site-packages/numpy/core/fromnumeric.py:83: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/home/pedro/.local/lib/python3.6/site-packages/ipykernel_launcher.py:13: RuntimeWarning: overflow encountered in square\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-f1a04dcd54e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0my3_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx3_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0my3_n_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx3_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthetaNormal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0merror3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my3_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my3_predict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0merror3_n\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my3_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my3_n_predict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/metrics/regression.py\u001b[0m in \u001b[0;36mmean_squared_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[1;32m    236\u001b[0m     \"\"\"\n\u001b[1;32m    237\u001b[0m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[0;32m--> 238\u001b[0;31m         y_true, y_pred, multioutput)\n\u001b[0m\u001b[1;32m    239\u001b[0m     output_errors = np.average((y_true - y_pred) ** 2, axis=0,\n\u001b[1;32m    240\u001b[0m                                weights=sample_weight)\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/metrics/regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    451\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[1;32m    452\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     42\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     43\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[0;32m---> 44\u001b[0;31m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "data = diamond_data[['x', 'y', 'z', 'carat', 'price']]\n",
    "data.insert(loc=0, column='x2', value = data['x']**2)\n",
    "data.insert(loc=0, column='y2', value = data['y']**2)\n",
    "data.insert(loc=0, column='z2', value = data['z']**2)\n",
    "data.insert(loc=0, column='carat2', value = data['carat']**2)\n",
    "x3,y3 = prepareSet(data)\n",
    "indices_generator = generate_sets(x3)\n",
    "theta3 = np.zeros((5,x3.shape[1],1))\n",
    "error3 = np.zeros((5,1))\n",
    "error3_n = np.zeros((5,1)) \n",
    "i=0\n",
    "for train_index, val_index in indices_generator:\n",
    "    #dados de treino e de validacao\n",
    "    x3_train = x3[train_index]\n",
    "    y3_train = y3[train_index]\n",
    "    x3_val = x3[val_index]\n",
    "    y3_val = y3[val_index]\n",
    "     \n",
    "    theta3[i] = LinRegBatchGradientDescent(x3_train,y3_train,10000,0.001)\n",
    "    thetaNormal = NormalEquation(x3_train,y3_train)\n",
    "    \n",
    "    #error from validation\n",
    "    y3_predict = x3_val.dot(theta3[i])\n",
    "    y3_n_predict = x3_val.dot(thetaNormal)\n",
    "    error3[i] = mean_squared_error(y3_val, y3_predict)\n",
    "    error3_n[i] = mean_squared_error(y3_val, y3_n_predict)/2\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=1)\n",
    "for i in range(5):\n",
    "    print(\"Iteracao \", i+1,)\n",
    "    print(\"\\tErro pelo Gradient Descent:\", int(error3[i]) )\n",
    "    print(\"\\tErro pela Equacao Normal:  \" , int(error3_n[i]) )\n",
    "\n",
    "print(\"Media erros GD:\", int(np.mean(error3)) )\n",
    "print(\"Media erros EN:\", int(np.mean(error3_n)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo 4: todas as features com tudo ao quadrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not invertible\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "data type not understood",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-a32761a6a41b>\u001b[0m in \u001b[0;36mNormalEquation\u001b[0;34m(X, y)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0minverse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmult1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36minv\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m    531\u001b[0m     \u001b[0mextobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_linalg_error_extobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m     \u001b[0mainv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_umath_linalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mainv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36m_raise_linalgerror_singular\u001b[0;34m(err, flag)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Singular matrix\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLinAlgError\u001b[0m: Singular matrix",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-9eaab898dfbb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mtheta4\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinRegBatchGradientDescent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx4_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my4_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mthetaNormal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNormalEquation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx4_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my4_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m#error from validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-a32761a6a41b>\u001b[0m in \u001b[0;36mNormalEquation\u001b[0;34m(X, y)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinAlgError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Not invertible\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: data type not understood"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "x4,y4 = prepareSet(diamond_data)\n",
    "x4 = np.hstack([x4,x4**2])\n",
    "indices_generator = generate_sets(x4)\n",
    "theta4 = np.zeros((5,x4.shape[1],1))\n",
    "error4 = np.zeros((5,1))\n",
    "error4_n = np.zeros((5,1)) \n",
    "i=0\n",
    "for train_index, val_index in indices_generator:\n",
    "    #dados de treino e de validacao\n",
    "    x4_train = x4[train_index]\n",
    "    y4_train = y4[train_index]\n",
    "    x4_val = x4[val_index]\n",
    "    y4_val = y4[val_index]\n",
    "     \n",
    "    theta4[i] = LinRegBatchGradientDescent(x4_train,y4_train,10000,0.0001)\n",
    "    thetaNormal = NormalEquation(x4_train,y4_train)\n",
    "    \n",
    "    #error from validation\n",
    "    y4_predict = x4_val.dot(theta4[i])\n",
    "    y4_n_predict = x4_val.dot(thetaNormal)\n",
    "    error4[i] = mean_squared_error(y4_val, y4_predict)\n",
    "    error4_n[i] = mean_squared_error(y4_val, y4_n_predict)/2\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=1)\n",
    "for i in range(5):\n",
    "    print(\"Iteracao \", i+1,)\n",
    "    print(\"\\tErro pelo Gradient Descent:\", int(error4[i]) )\n",
    "    print(\"\\tErro pela Equacao Normal:  \" , int(error4_n[i]) )\n",
    "\n",
    "print(\"Media erros GD:\", int(np.mean(error4)) )\n",
    "print(\"Media erros EN:\", int(np.mean(error4_n)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
