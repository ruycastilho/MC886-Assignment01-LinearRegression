{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def load_diamond_data():\n",
    "    csv_path = os.path.join(\"diamonds-dataset\", \"diamonds-train.csv\")\n",
    "    return pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carrega os dados de treino e faz feature scaling(depth, table)\n",
    "import numpy as np\n",
    "diamond_data = load_diamond_data()\n",
    "diamond_data[\"depth\"] = (diamond_data[\"depth\"] / 10)\n",
    "diamond_data[\"table\"] = (diamond_data[\"table\"] / 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#dummy coding(cut,color,clarity)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "diamond_data = load_diamond_data()\n",
    "diamond_data[\"depth\"] = diamond_data[\"depth\"] / 10\n",
    "diamond_data[\"table\"] = diamond_data[\"table\"] / 10\n",
    "\n",
    "enumValues = {\"cut\": {\"Fair\":0, \"Good\":1, \"Very Good\":2, \"Premium\":3, \"Ideal\":4},\n",
    "              \"color\": {\"J\": 0, \"I\":1, \"H\":2, \"G\":3, \"F\":4, \"E\":5, \"D\":6},\n",
    "              \"clarity\": {\"I1\":0, \"SI2\":1, \"SI1\":2, \"VS2\":3, \"VS1\":4,\"VVS2\":5, \"VVS1\":6, \"IF\":7}}\n",
    "diamond_data.replace(enumValues, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal Equation\n",
    "\n",
    "def NormalEquation(X, y):\n",
    "\n",
    "    transpose = X.T\n",
    "\n",
    "    mult1 = transpose.dot(X)\n",
    "\n",
    "    try:\n",
    "        inverse = np.linalg.inv(mult1)\n",
    "\n",
    "    except np.linalg.LinAlgError:\n",
    "        print(\"Not invertible\")\n",
    "        return np.zeros(1,1)\n",
    "\n",
    "    else:\n",
    "        mult2 = (inverse.dot(transpose)).dot(y)\n",
    "        return mult2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#function add a first column filled with 1's and delete de last colum\n",
    "def prepareSet(setToPrepare):\n",
    "    X = np.array(setToPrepare)\n",
    "\n",
    "    X = np.delete(X, -1, axis=1)\n",
    "\n",
    "    X = np.c_[np.ones((len(X), 1)),X]\n",
    "\n",
    "    y = np.array(setToPrepare[\"price\"])\n",
    "\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #grafico Carat X Price\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.scatter(diamond_data[\"carat\"], diamond_data[\"price\"])\n",
    "# plt.xlabel(\"$carat$\", fontsize=18)\n",
    "# plt.ylabel(\"$price(U$)$\", fontsize=18)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #grafico Cut X Price\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.scatter(diamond_data[\"cut\"], diamond_data[\"price\"])\n",
    "# plt.xlabel(\"$cut$\", fontsize=18)\n",
    "# plt.ylabel(\"$price$\", fontsize=18)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #grafico  Color X Price\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.scatter(diamond_data[\"color\"], diamond_data[\"price\"])\n",
    "# plt.xlabel(\"$color$\", fontsize=18)\n",
    "# plt.ylabel(\"$price$\", fontsize=18)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #grafico Clarity X Price\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.scatter(diamond_data[\"clarity\"], diamond_data[\"price\"])\n",
    "# plt.xlabel(\"$clarity$\", fontsize=18)\n",
    "# plt.ylabel(\"$price$\", fontsize=18)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #grafico Depth X Price\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.scatter(diamond_data[\"depth\"], diamond_data[\"price\"])\n",
    "# plt.xlabel(\"$depth$\", fontsize=18)\n",
    "# plt.ylabel(\"$price$\", fontsize=18)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #grafico table X Price\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.scatter(diamond_data[\"table\"], diamond_data[\"price\"])\n",
    "# plt.xlabel(\"$table$\", fontsize=18)\n",
    "# plt.ylabel(\"$price$\", fontsize=18)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #grafico x X Price\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.scatter(diamond_data[\"x\"], diamond_data[\"price\"])\n",
    "# plt.xlabel(\"$x$\", fontsize=18)\n",
    "# plt.ylabel(\"$price$\", fontsize=18)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #grafico y X Price\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.scatter(diamond_data[\"y\"], diamond_data[\"price\"])\n",
    "# plt.xlabel(\"$y$\", fontsize=18)\n",
    "# plt.ylabel(\"$price$\", fontsize=18)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #grafico z X Price\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.scatter(diamond_data[\"z\"], diamond_data[\"price\"])\n",
    "# plt.xlabel(\"$z$\", fontsize=18)\n",
    "# plt.ylabel(\"$price$\", fontsize=18)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation Generation\n",
    "\n",
    "# PRECISA CHAMAR ISSO ANTES DE CHAMAR A FUNCAO --- \n",
    "#                             TRAINING_DATA = prepareSet(diamond_data) \n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "#essa funcao retorna um gerador de indices\n",
    "def generate_sets(TRAINING_DATA,type='kfold'):\n",
    "\n",
    "    # Cross validation using train_test_split\n",
    "    if (type == 'split'):\n",
    "       return train_test_split(TRAINING_DATA,test_size=0.2,random_state=0)\n",
    "\n",
    "    # Cross validation using K-Fold\n",
    "    # K = 5, Shuffle = true, Seed = 21\n",
    "    elif (type == 'kfold'):\n",
    "        kfold_seed = 21\n",
    "\n",
    "        kfold = KFold(n_splits=5, shuffle=True, random_state=kfold_seed)\n",
    "        return kfold.split(TRAINING_DATA)\n",
    "#         for train_index, test_index in kfold.split(X):\n",
    "#             X_train, X_test = X[train_index], X[test_index]\n",
    "#             y_train, y_test = y[train_index], y[test_index]\n",
    "#             print(\"TRAIN:\", X_train.shape, \"TEST:\", X_test.shape)\n",
    "#             print(\"TEST:\", y_train.shape, \"TEST:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explicação do uso do generate_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import numpy as np\n",
    "# from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "# X = np.array([[10, 20], [30, 40], [50, 60], [70, 80], [90, 100], [110, 120], [130, 140], [150, 160], [170, 180], [190, 200]])\n",
    "# y = np.array(['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j'])\n",
    "\n",
    "# #esse b vai ser um gerador, não precisa passar y pois ele gera somente os indices\n",
    "# b = generate_sets(X)\n",
    "\n",
    "# #precisa percorrer ele com 2 indices, um representa o treino, outro o test, \n",
    "# # na proxima iteracao ele ja vai estar num agrupamento diferente\n",
    "# for train_index, test_index in b:\n",
    "#     x_train = X[train_index]\n",
    "#     y_train = y[train_index]\n",
    "#     x_test = X[test_index]\n",
    "#     y_test = y[test_index]\n",
    "#     print(x_train, y_train)\n",
    "#     print(x_test, y_test)\n",
    "#     print(\"-----\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# #Scikit-Learn Linear Regression using Stochastic Gradient Descent(SGD) for comparisson\n",
    "# from sklearn.linear_model import SGDRegressor\n",
    "# sgd_reg = SGDRegressor(max_iter = 100, eta0=0.1)\n",
    "# sgd_reg.fit(X_train, y_train)\n",
    "# sgd_reg.intercept_, sgd_reg.coef_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for train_index, validate_index in generate_sets():\n",
    "#     X_train, X_test = X[train_index], X[validate_index]\n",
    "#     y_train, y_test = y[train_index], y[validate_index]\n",
    "#     print(LinRegBatchGradientDescent(X_train,y_train.reshape(len(y_train),1),100,0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_schedule(t):\n",
    "    return t0 / (t + t1)\n",
    "#TODO\n",
    "#implementation Linear Regression using Stochastick Gradient Descent(SGD)\n",
    "def LinRegStochasticGradientDescent(TRAIN_SET, TARGET_SET, N_EPOCHS, LEARNING_RATE):\n",
    "    t0, t1 = 5, 50  # learning schedule hyperparameters\n",
    "    theta = np.random.randn(len(TRAIN_SET),1)  # random initialization\n",
    "    for epoch in range(N_EPOCHS):\n",
    "        for i in range(m):\n",
    "            random_index = np.random.randint(m)\n",
    "            xi = TRAIN_SET[random_index:random_index+1]\n",
    "            yi = TARGET_SET[random_index:random_index+1]\n",
    "            gradients = 2 * xi.T.dot(xi.dot(theta) - yi)\n",
    "            #eta = learning_schedule(epoch * m + i)\n",
    "            #theta = theta - eta * gradients\n",
    "            theta = theta - LEARNING_RATE * gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implementation Linear Regression using Mini-Batch Gradient Descent\n",
    "def LinRegMiniGradientDescent(TRAIN_SET, TARGET_SET, N_ITERATION, LEARNING_RATE, SIZE_BATCH):\n",
    "    np.random.seed(42)\n",
    "    theta = np.random.randn(10,1) #random initialization\n",
    "    for iteration in range(N_ITERATIONS):\n",
    "        shuffle_indices = np.random.permutation(TRAIN_SET.shape[0])\n",
    "        train_shuffled = TRAIN_SET[shuffled_indices]\n",
    "        target_shuffled = TARGET_SET[shuffled_indices]\n",
    "        for i in range(0,TARGET_SET.shape[0], SIZE_BATCH):\n",
    "            xi = train_shuffled[i:i+SIZE_BATCH]\n",
    "            yi = target_shuffled[i:i+SIZE_BATCH]\n",
    "            gradients = 2/SIZE_BATCH * xi.T.dot(xi.dot(theta) - yi)\n",
    "            theta = theta - LEARNING_RATE * gradients\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 4, 6, 7, 1, 5, 3])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1,2,3,4,5,6,7])\n",
    "shuffle_indices = np.random.permutation(7)\n",
    "train_shuffled = a[shuffle_indices]\n",
    "train_shuffled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### duvidas\n",
    "funcao stochastic, nao entendi o for i in range(m), não era pra fazer so pra 1?\n",
    "<br>\n",
    "funcao mini, na hora de calcular o gradiente nao sera mais pra dividir por m, agora e pra dividir por size_batch\n",
    "<br>\n",
    "na funcao da professora, tem um x^(i) multiplicando o theta 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ideias de modelos\n",
    "usando todas as features\n",
    "<br>\n",
    "&nbsp;&nbsp;normal\n",
    "&nbsp;&nbsp;ao quadrado\n",
    "<br>\n",
    "tirando as features que nao aparentam influenciar\n",
    "<br>\n",
    "&nbsp;&nbsp;normal\n",
    "&nbsp;&nbsp; ao quadrado\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#Linear Regression using batch gradient descent\n",
    "#ex n_iterations = 10000, learning_rate = 0.1\n",
    "def LinRegBatchGradientDescent(TRAIN_SET, TARGET_SET, N_ITERATIONS, LEARNING_RATE):\n",
    "    theta = np.random.randn(TRAIN_SET.shape[1],1) #random initialization\n",
    "    m = TRAIN_SET.shape[0]\n",
    "    for iteration in range(N_ITERATIONS):\n",
    "        gradients = 2/m * TRAIN_SET.T.dot(TRAIN_SET.dot(theta) - TARGET_SET)\n",
    "        theta = theta - LEARNING_RATE * gradients\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proximos 4 celulas e pra mostrar que o nosso Lin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "##DATA SET PARA testar A FUNCAO DEPOIS\n",
    "import numpy as np\n",
    "import numpy.random as rnd\n",
    "\n",
    "np.random.seed(42)\n",
    "X = 2 * rnd.rand(100,1)\n",
    "y = 4 + 3 * X + rnd.randn(100,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.21509616],\n",
       "       [2.77011339]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy.linalg as LA\n",
    "\n",
    "X_b = np.c_[np.ones((100, 1)), X] # add x0 = 1 to each instance\n",
    "theta_best = LA.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y)\n",
    "theta_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4.2183988]), array([2.77639722]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "sgd_reg = SGDRegressor(max_iter=1000, penalty=None, eta0=0.1)\n",
    "sgd_reg.fit(X, y.ravel())\n",
    "sgd_reg.intercept_, sgd_reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.21509616]\n",
      " [2.77011339]]\n"
     ]
    }
   ],
   "source": [
    "# print(x1)\n",
    "print(LinRegBatchGradientDescent(X_b,y,1000,0.1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
